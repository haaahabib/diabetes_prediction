# -*- coding: utf-8 -*-
"""Machine Leerning Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EJ7dnXkDM55E1_nBlQl_B8SXryT0Cw6a

## Project Pertama Machine Learning Terapan
- Nama: Muhammad Habibulloh
- ID Dicoding: MC258D5Y1827

### Prediksi Risiko Diabetes
- Bidang: Kesehatan
- Pima Indians Diabetes Database
- [Link Dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)

### Setup Environment & Load Data

#### Instal Library
"""

!pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn

"""#### Import Library"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

"""#### Load Dataset"""

# Load file CSV
df = pd.read_csv('diabetes.csv')

# Cek data
print("Jumlah data:", len(df))
df.head()

"""### Eksplorasi Data (EDA)"""

# Cek informasi dataset
print(df.info())

"""Menampilkan informasi tentang dataset, seperti kolom, tipe data, dan jumlah kolom (9)"""

# Cek missing value
print(df.isnull().sum())

# Jumlah pasien diabetes dan non-diabetes
num_diabetes = df['Outcome'].value_counts()[1]
num_non_diabetes = df['Outcome'].value_counts()[0]

print(f"Jumlah pasien diabetes: {num_diabetes}")
print(f"Jumlah pasien non-diabetes: {num_non_diabetes}")

# Distribusi kelas
plt.figure(figsize=(6,4))
sns.countplot(x='Outcome', data=df)
plt.title('Distribusi Pasien Diabetes vs Non-Diabetes')
plt.show()

"""### Distribusi Pasien Diabetes vs Non-Diabetes

Grafik di atas menunjukkan distribusi awal pasien diabetes dan non-diabetes dalam dataset. Dapat dilihat bahwa jumlah pasien non-diabetes (500) lebih banyak dibandingkan pasien diabetes (268). Ketidakseimbangan kelas ini ditangani dengan menggunakan teknik oversampling SMOTE sebelum pelatihan model, sehingga distribusi kelas pada data latih menjadi seimbang.
"""

# Korelasi fitur
plt.figure(figsize=(10,6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Korelasi Antar Fitur')
plt.show()

"""### Korelasi dengan Outcome

1. **Glucose** (0.47)  
   Korelasi tertinggi dengan Outcome. Kadar glukosa tinggi merupakan indikator utama diabetes.

2. **BMI** (0.29)  
   Indeks massa tubuh tinggi berkaitan dengan peningkatan risiko diabetes.

3. **Age** (0.24)  
   Usia semakin tinggi cenderung memiliki risiko lebih besar.

4. **Pregnancies** (0.22)  
   Jumlah kehamilan berpengaruh pada risiko diabetes.


### Korelasi Terendah:
1. BloodPressure (Tekanan Darah diastolik) vs Outcome (0.07)
2. DiabetesPedigreeFunction (Riwayat diabetes dalam keluarga pasien) vs Outcome (0.17)

###  Persiapan Data

Kode untuk mengganti nilai 0 dengan NaN dan mengisi nilai NaN dengan median pada kolom-kolom tertentu. Tahap ini dilakukan untuk membersihkan data dan menangani missing value. Namun pada data yang saya gunakan tidak ada missing value, jadi ini opsional
"""

# Opsional karena tidak ditemukan missing value pada # Cek missing value
# Mengganti nilai 0 dengan NaN
columns_to_clean = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']
df[columns_to_clean] = df[columns_to_clean].replace(0, np.nan)

# Mengisi nilai NaN dengan median
df.fillna(df.median(), inplace=True)

"""#### Data Splitting

Membagi data menjadi data latih (train) dan data uji (test) dengan rasio 80:20.
"""

# Data Splitting
X = df.drop('Outcome', axis=1)
y = df['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Data Splitting:")
print(f"Jumlah data train (X_train): {X_train.shape[0]}")
print(f"Jumlah data test (X_test): {X_test.shape[0]}")
print(f"Jumlah target train (y_train): {y_train.shape[0]}")
print(f"Jumlah target test (y_test): {y_test.shape[0]}")

"""#### Scaling

Melakukan scaling data menggunakan StandardScaler yang bertujuan untuk menyamakan skala antar fitur
"""

# Scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""#### Data Imbalance

Menggunakan teknik SMOTE untuk mengatasi ketidakseimbangan kelas pada data train
"""

# Penanganan data tidak seimbang
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

"""### Modelling

Menggunakan 3 model machine learning

1. Logistic Regression
2. Random Forest
3. Gradient Boosting
"""

# Inisialisasi model
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier()
}

"""#### Pelatihan Model"""

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    print(f"{name}")
    print(f"Akurasi: {acc:.2f}")
    print(classification_report(y_test, y_pred))
    print("="*50)

    results[name] = acc

"""Random Forest memiliki performa terbaik dengan akurasi 0.77, kemudian dibawahnya yaitu Gradient Boosting dan Logistic Regression. Metrik presisi, recall, dan F1-score juga menunjukkan bahwa Random Forest memberikan hasil yang lebih baik secara keseluruhan.

#### Hyperparameter Tuning

Menggunakan GridSearchCV untuk mencari hyperparameter terbaik untuk model Random Forest
"""

# Tuning Random Forest
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5]
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
print("Akurasi Terbaik:", accuracy_score(y_test, y_pred))

"""### Evaluasi Model"""

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix Model Terbaik')
plt.show()

"""### Keterangan:
- **True Negative (TN)**: 41 Pasien non-diabetes diprediksi benar sebagai non-diabetes
- **False Positive (FP)**: 14 Pasien non-diabetes salah diprediksi sebagai diabetes
- **False Negative (FN)**: 22 Pasien diabetes salah diprediksi sebagai non-diabetes
- **True Positive (TP)**: 77 Pasien diabetes diprediksi benar sebagai diabetes
"""

# Perbandingan Model
pd.DataFrame({
    'Model': list(results.keys()) + ['Tuned Random Forest'],
    'Akurasi': list(results.values()) + [accuracy_score(y_test, y_pred)]
}).sort_values(by='Akurasi', ascending=False)

"""Meskipun tuning tidak meningkatkan akurasi, hal ini tetap memberikan informasi penting bahwa hyperparameter default Random Forest sudah cukup optimal untuk dataset ini.

Penggunaan Grid Search memastikan bahwa kita telah mengeksplorasi kemungkinan kombinasi hyperparameter dan memilih yang terbaik.

### Menyimpan Model

Menyimpan model terbaik ke dalam file 'model_diabetes.pkl' agar dapat digunakan kembali di kemudian hari
"""

import joblib
joblib.dump(best_model, 'model_diabetes.pkl')